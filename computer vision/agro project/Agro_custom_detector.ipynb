{"cells":[{"cell_type":"code","execution_count":1,"id":"45576825","metadata":{"id":"45576825","executionInfo":{"status":"ok","timestamp":1748371587750,"user_tz":360,"elapsed":12451,"user":{"displayName":"Alejo Agustin Alegre Bustos","userId":"16199469896058006662"}}},"outputs":[],"source":["\n","# ✅ Instalación mínima\n","!pip install -q opencv-python-headless tensorflow\n"]},{"cell_type":"code","execution_count":2,"id":"54b8dd19","metadata":{"id":"54b8dd19","executionInfo":{"status":"ok","timestamp":1748371693451,"user_tz":360,"elapsed":5989,"user":{"displayName":"Alejo Agustin Alegre Bustos","userId":"16199469896058006662"}}},"outputs":[],"source":["\n","import os\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow.keras import layers, models, Input\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from sklearn.model_selection import train_test_split\n"]},{"cell_type":"code","execution_count":3,"id":"dea474e7","metadata":{"id":"dea474e7","executionInfo":{"status":"ok","timestamp":1748371696539,"user_tz":360,"elapsed":22,"user":{"displayName":"Alejo Agustin Alegre Bustos","userId":"16199469896058006662"}}},"outputs":[],"source":["\n","# ✅ Rutas de imágenes y anotaciones YOLO\n","img_dir = \"/content/drive/MyDrive/yolov8/images/train/images\"\n","lbl_dir = \"/content/drive/MyDrive/yolov8/images/train/labels\"\n"]},{"cell_type":"code","execution_count":7,"id":"6cc2d2d0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6cc2d2d0","executionInfo":{"status":"ok","timestamp":1748372857381,"user_tz":360,"elapsed":539622,"user":{"displayName":"Alejo Agustin Alegre Bustos","userId":"16199469896058006662"}},"outputId":"58dcabca-098f-4b15-dbf6-63b268cb5f07"},"outputs":[{"output_type":"stream","name":"stdout","text":["Datos cargados: (800, 128, 128, 3)\n"]}],"source":["# ✅ Leer imágenes y anotaciones para regresión de bounding boxes\n","def load_detection_data(img_dir, lbl_dir, target_size=(128, 128), max_imgs=1000):\n","    X, Y = [], []  # Usamos Y en lugar de y para evitar conflicto de nombre\n","    for fname in os.listdir(lbl_dir)[:max_imgs]:\n","        if not fname.endswith('.txt'):\n","            continue\n","        img_name = fname.replace('.txt', '.jpg')\n","        img_path = os.path.join(img_dir, img_name)\n","        lbl_path = os.path.join(lbl_dir, fname)\n","\n","        if not os.path.exists(img_path):\n","            continue\n","\n","        img = cv2.imread(img_path)\n","        if img is None:\n","            continue\n","\n","        h0, w0 = img.shape[:2]\n","        img_resized = cv2.resize(img, target_size)\n","        img_resized = img_resized / 255.0\n","\n","        with open(lbl_path, 'r') as f:\n","            line = f.readline().strip().split()\n","            if len(line) != 5:\n","                continue  # clase, x, y, w, h\n","            _, cx, cy, w, h = map(float, line)  # Renombramos para evitar conflicto\n","            box = [cx, cy, w, h]\n","\n","        X.append(img_resized)\n","        Y.append(box)\n","\n","    return np.array(X), np.array(Y)\n","\n","# Usamos variables finales X, y (que no entran en conflicto dentro de la función)\n","X, y = load_detection_data(img_dir, lbl_dir)\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n","print(\"Datos cargados:\", X_train.shape)\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wgdX-VMqFAWV","executionInfo":{"status":"ok","timestamp":1748371804884,"user_tz":360,"elapsed":22341,"user":{"displayName":"Alejo Agustin Alegre Bustos","userId":"16199469896058006662"}},"outputId":"0bd2db6d-cf6e-4d58-d260-ae010f369ddd"},"id":"wgdX-VMqFAWV","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"id":"4ab2c610","metadata":{"id":"4ab2c610"},"outputs":[],"source":["\n","def build_object_detector():\n","    inputs = Input(shape=(128, 128, 3))\n","    x = layers.Conv2D(32, 3, activation='relu')(inputs)\n","    x = layers.MaxPooling2D()(x)\n","    x = layers.Conv2D(64, 3, activation='relu')(x)\n","    x = layers.MaxPooling2D()(x)\n","    x = layers.Flatten()(x)\n","    x = layers.Dense(128, activation='relu')(x)\n","    outputs = layers.Dense(4, activation='sigmoid')(x)  # x, y, w, h\n","    return models.Model(inputs, outputs)\n","\n","detector = build_object_detector()\n","detector.compile(optimizer='adam', loss='mse')\n"]},{"cell_type":"code","execution_count":null,"id":"b6f53ea2","metadata":{"id":"b6f53ea2"},"outputs":[],"source":["\n","detector.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n"]},{"cell_type":"code","execution_count":null,"id":"00575501","metadata":{"id":"00575501"},"outputs":[],"source":["\n","def create_custom_classifier(num_classes):\n","    inputs = Input(shape=(128, 128, 3))\n","    x = layers.Conv2D(16, (3, 3), activation='relu')(inputs)\n","    x = layers.MaxPooling2D()(x)\n","    x = layers.Conv2D(32, (3, 3), activation='relu')(x)\n","    x = layers.MaxPooling2D()(x)\n","    x = layers.Flatten()(x)\n","    x = layers.Dropout(0.3)(x)\n","    x = layers.Dense(64, activation='relu')(x)\n","    outputs = layers.Dense(num_classes, activation='softmax')(x)\n","    return models.Model(inputs, outputs)\n"]},{"cell_type":"code","execution_count":null,"id":"2a7dca89","metadata":{"id":"2a7dca89"},"outputs":[],"source":["\n","# Supongamos que ya tenemos un modelo de clasificación entrenado\n","# cnn_model = create_custom_classifier(num_classes=12)\n","# cnn_model.load_weights('/content/drive/MyDrive/Model_Checkpoints/best_model.h5')\n","\n","def detectar_y_clasificar_custom(img_path, detector, classifier):\n","    img = cv2.imread(img_path)\n","    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    img_resized = cv2.resize(img_rgb, (128, 128)) / 255.0\n","    input_array = np.expand_dims(img_resized, axis=0)\n","\n","    pred_box = detector.predict(input_array)[0]\n","    h, w = img.shape[:2]\n","\n","    cx, cy, bw, bh = pred_box\n","    x1 = int((cx - bw / 2) * w)\n","    y1 = int((cy - bh / 2) * h)\n","    x2 = int((cx + bw / 2) * w)\n","    y2 = int((cy + bh / 2) * h)\n","\n","    crop = img_rgb[max(0,y1):min(h,y2), max(0,x1):min(w,x2)]\n","    if crop.size == 0:\n","        print(\"Recorte inválido.\")\n","        return\n","    crop_resized = cv2.resize(crop, (128, 128)) / 255.0\n","    crop_input = np.expand_dims(crop_resized, axis=0)\n","\n","    pred = classifier.predict(crop_input)\n","    class_id = np.argmax(pred)\n","    confidence = np.max(pred)\n","    print(f\"Clase: {class_id}, Confianza: {confidence:.2f}\")\n"]}],"metadata":{"colab":{"provenance":[]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}